name: publish
on:
  push:
    branches:
      - "release/**" # Staging deployment
    tags:
      - "v*" # Version tags (e.g., v1.0.0, v2.1.5)
  workflow_dispatch: # Allow manual triggers

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ghcr.io/${{ github.actor }}/dealership

jobs:
  publish:
    name: Publish Docker Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.set-tag.outputs.tag }}
      version-tag: ${{ steps.set-tag.outputs.version }}
      app-url: ${{ steps.set-tag.outputs.app-url }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      # *** FIX 1: Using $GITHUB_OUTPUT instead of ::set-output to eliminate deprecation warnings ***
      - name: Determine image tag, environment, and APP_URL
        id: set-tag
        run: |
          # Define URLs based on your provided .env files
          STAGING_URL="https://dealership.monatemedia.com"
          PRODUCTION_URL="https://actuallyfind.com"
          if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
            VERSION="${GITHUB_REF#refs/tags/v}"
            # Use GITHUB_OUTPUT file for production tag
            echo "tag=production" >> $GITHUB_OUTPUT
            echo "version=$VERSION" >> $GITHUB_OUTPUT
            echo "app-url=$PRODUCTION_URL" >> $GITHUB_OUTPUT
            echo "üì¶ Building tagged release: v$VERSION"
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            LATEST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "0.0.0")
            VERSION="${LATEST_TAG#v}"
            # Use GITHUB_OUTPUT file for main branch production tag
            echo "tag=production" >> $GITHUB_OUTPUT
            echo "version=$VERSION" >> $GITHUB_OUTPUT
            echo "app-url=$PRODUCTION_URL" >> $GITHUB_OUTPUT
            echo "üöÄ Building production from tag: $LATEST_TAG"
          elif [[ "${{ github.ref }}" == refs/heads/release/* ]]; then
            VERSION="${GITHUB_REF#refs/heads/release/}"
            # Use GITHUB_OUTPUT file for staging tag
            echo "tag=staging" >> $GITHUB_OUTPUT
            echo "version=$VERSION" >> $GITHUB_OUTPUT
            echo "app-url=$STAGING_URL" >> $GITHUB_OUTPUT
            echo "üß™ Building staging release: $VERSION"
          else
            VERSION="dev-$(git rev-parse --short HEAD)"
            # Use GITHUB_OUTPUT file for dev tag
            echo "tag=dev" >> $GITHUB_OUTPUT
            echo "version=$VERSION" >> $GITHUB_OUTPUT
            echo "app-url=$STAGING_URL" >> $GITHUB_OUTPUT
            echo "üîß Building development: $VERSION"
          fi
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Login to GitHub Container Registry
        run: |
          echo ${{ secrets.PAT }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - name: Build and Push Docker Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: |
            ${{ env.IMAGE_NAME }}:${{ steps.set-tag.outputs.tag }}
            ${{ env.IMAGE_NAME }}:v${{ steps.set-tag.outputs.version }}
            ${{ env.IMAGE_NAME }}:${{ github.sha }}
          cache-from: type=registry,ref=${{ env.IMAGE_NAME }}:buildcache
          cache-to: type=registry,ref=${{ env.IMAGE_NAME }}:buildcache,mode=max
          build-args: |
            INSTALL_DEV_DEPENDENCIES=${{ contains(github.ref, 'refs/heads/release/') }}
      - name: Output deployment info
        run: |
          echo "üìå Version: ${{ steps.set-tag.outputs.version }}"
          echo "üåê APP URL: ${{ steps.set-tag.outputs.app-url }}"
          echo "üè∑Ô∏è  Image Tags:"
          echo "   ‚Ä¢ ${{ env.IMAGE_NAME }}:${{ steps.set-tag.outputs.tag }}"
          echo "   ‚Ä¢ ${{ env.IMAGE_NAME }}:v${{ steps.set-tag.outputs.version }}"
          echo "   ‚Ä¢ ${{ env.IMAGE_NAME }}:${{ github.sha }}"

  deploy-staging:
    needs: publish
    name: Deploy to Staging
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/heads/release/')
    # Map existing secrets and hardcoded values for the script
    env:
      APP_URL: ${{ needs.publish.outputs.app-url }}
      VERSION: ${{ needs.publish.outputs.version-tag }}
      HOST: ${{ secrets.SSH_HOST }}
      USER: ${{ secrets.SSH_USER }}
      SSH_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
      WORK_DIR: ${{ secrets.WORK_DIR }}
      # Hardcoded static service names used in the staging docker-compose.yml
      WEB_SERVICE: dealership-web
      QUEUE_SERVICE: dealership-queue
      SETUP_INIT_SERVICE: dealership-init
      SETUP_DEMO_SERVICE: dealership-demo
      HOST_PORT: 8090 # DOCKER_LARAVEL_PORT from dealership/.env
    steps:
      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ env.SSH_KEY }}
      - name: Add Server to Known Hosts
        run: ssh-keyscan -H ${{ env.HOST }} >> ~/.ssh/known_hosts
      - name: Pull, Setup, and Deploy to Staging
        run: |
          ssh ${{ env.USER }}@${{ env.HOST }} << 'EOF'
            # 1. Change to the application directory
            cd ${{ env.WORK_DIR }} || exit 1
            # 2. Define the image tag and pull the latest image
            DEPLOY_TAG=${{ needs.publish.outputs.image-tag }}
            FULL_IMAGE_NAME="${{ env.IMAGE_NAME }}:${DEPLOY_TAG}"
            echo "üì• Pulling latest image: ${FULL_IMAGE_NAME}"
            docker pull ${FULL_IMAGE_NAME}
            # 3. Export the Image Tag for docker-compose to use
            # This assumes your remote docker-compose file uses APP_IMAGE_TAG or similar
            export APP_IMAGE_TAG=${DEPLOY_TAG}
            # 4. Stop all existing services
            docker compose down
            # 5. Start the main application services
            docker compose up -d ${WEB_SERVICE} ${QUEUE_SERVICE}
            echo "‚è≥ Waiting for web container to boot..."
            sleep 15
          EOF
      - name: External Health Check
        run: |
          echo "üåê Performing external health check..."
          sleep 5
          response=$(curl -s -o /dev/null -w "%{http_code}" ${{ env.APP_URL }} || echo "000")
          if [ "$response" = "200" ]; then
            echo "‚úÖ External health check passed (HTTP $response)"
          else
            echo "‚ùå External health check failed (HTTP $response) at ${{ env.APP_URL }}"
            exit 1
          fi
      - name: Cleanup SSH Keys
        if: always()
        run: rm -rf ~/.ssh

  deploy-production:
    needs: publish
    name: Deploy to Production
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')
    environment: "production"
    # Grant write permissions for creating GitHub Releases
    permissions:
      contents: write

    # Map existing secrets and hardcoded values for the script
    env:
      BASE_DOMAIN: actuallyfind.com
      APP_URL: ${{ needs.publish.outputs.app-url }}
      VERSION: ${{ needs.publish.outputs.version-tag }}
      HOST: ${{ secrets.PRODUCTION_HOST }}
      USER: ${{ secrets.PRODUCTION_USER }}
      SSH_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
      WORK_DIR: ${{ secrets.PRODUCTION_WORK_DIR }}

      # Service base names
      WEB_SERVICE_BASE: actuallyfind-web
      QUEUE_SERVICE: actuallyfind-queue
      DB_SERVICE: actuallyfind-db
      TYPESENSE_SERVICE: actuallyfind-typesense

      # --- NEW PRODUCTION PORTS (Host-side port mappings) ---
      DOCKER_LARAVEL_PORT: 8100
      DOCKER_POSTGRES_PORT: 5445
      DOCKER_ADMINER_PORT: 8101
      DOCKER_TYPESENSE_PORT: 8118
      # -----------------------------------------------------

    steps:
      # 1. Checkout Application Code (gets the code tied to the tag/trigger)
      - name: Checkout Application Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          # Application code is checked out into a subdirectory to keep the root clean
          path: app-code

      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ env.SSH_KEY }}

      - name: Add Production Server to Known Hosts
        run: |
          # Use -T 1 to set a timeout, and check the command's exit code
          ssh-keyscan -v -H ${{ env.HOST }} 2>&1 >> ~/.ssh/known_hosts
          if [ $? -ne 0 ]; then
            echo "üö® Error: ssh-keyscan failed to retrieve key from ${{ env.HOST }}. Check the host address and firewall rules."
            exit 1
          else
            echo "‚úÖ Successfully added host key."
          fi

      - name: üåê Ensure External Docker Network Exists
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.HOST }}
          username: ${{ env.USER }}
          key: ${{ env.SSH_KEY }}
          script: |
            # Check if the network 'proxy-network' exists. If not, create it.
            # This is essential for the containers to connect to the external Nginx proxy.
            docker network create proxy-network || true
            echo "‚úÖ Ensured 'proxy-network' exists for external proxy connection."

      - name: üöÄ Start Nginx Reverse Proxy Stack
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.HOST }}
          username: ${{ env.USER }}
          key: ${{ env.SSH_KEY }}
          script: |
            NGINX_PROXY_DIR="/home/${{ env.USER }}/nginx-proxy"

            echo "Checking and starting Nginx Proxy stack in ${NGINX_PROXY_DIR}..."

            # Use 'docker compose ps -q' to see if any containers in this stack are running.
            # If the output is empty, start the stack.
            if [ -z "$(docker compose -f ${NGINX_PROXY_DIR}/docker-compose.yml ps -q)" ]; then
              echo "Nginx Proxy stack not running. Starting containers..."
              docker compose -f ${NGINX_PROXY_DIR}/docker-compose.yml up -d
              echo "‚úÖ Nginx Proxy stack started."
            else
              echo "Nginx Proxy stack already running."
            fi

      # --- UPDATED CREATE .env FILE (Using Here-Doc for safety) ---
      # This step now focuses on writing the secrets and static config,
      # but NOT the port mappings, as they are passed directly to docker compose.
      - name: üìù Create Production .env file on VPS
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.HOST }}
          username: ${{ env.USER }}
          key: ${{ env.SSH_KEY }}
          script: |
            cd ${{ env.WORK_DIR }}
            # --- NEW LOGIC: READ AND PRESERVE EXISTING APP_KEY ---
            EXISTING_APP_KEY=$(grep '^APP_KEY=' .env 2>/dev/null)

            # Use Here-Doc to securely write the application secrets and static config.
            cat << EOF > .env
            # Application Secrets (Critical for Laravel/App)
            # APP_KEY is intentionally omitted here; it is preserved or generated later.
            DB_PASSWORD=${{ secrets.PRODUCTION_DB_PASSWORD }}
            TYPESENSE_API_KEY=${{ secrets.PRODUCTION_TYPESENSE_API_KEY }}

            # üîë AWS SES SDK Configuration (Uses IAM Keys)
            AWS_ACCESS_KEY_ID=${{ secrets.PRODUCTION_AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.PRODUCTION_AWS_SECRET_ACCESS_KEY }}
            AWS_REGION=eu-north-1
            AWS_DEFAULT_REGION=eu-north-1

            # üì¨ Mailer Configuration: Use 'ses' driver to utilize the IAM keys above!
            MAIL_MAILER=ses
            # MAIL_HOST, MAIL_PORT, MAIL_USERNAME, MAIL_PASSWORD are NOT needed for 'ses' mailer.
            MAIL_ENCRYPTION=tls
            MAIL_FROM_ADDRESS=noreply@actuallyfind.com
            MAIL_FROM_NAME=${APP_NAME}

            # Static Application Configuration
            DOCKER_CONTAINER_NAME=actuallyfind
            ENVIRONMENT=production
            BASE_DOMAIN=actuallyfind.com
            APP_NAME=ActuallyFind
            APP_ENV=production
            APP_DEBUG=false
            APP_URL=${{ env.APP_URL }}
            SEED_DATABASE=false
            # Internal Database Config (used by Laravel)
            DB_CONNECTION=pgsql
            DB_HOST=actuallyfind-db
            DB_PORT=5432
            DB_DATABASE=actuallyfind_db
            DB_USERNAME=ACTUAL_PROD_DB_USER
            # Internal Typesense Config (used by Laravel)
            TYPESENSE_HOST=actuallyfind-typesense
            TYPESENSE_PORT=8108
            # The key Laravel will look for:
            TYPESENSE_API_KEY=${{ secrets.PRODUCTION_TYPESENSE_API_KEY }}
            # Add other static config here (MAIL_USERNAME, GOOGLE_CLIENT_ID, etc.)
            MAIL_USERNAME=ACTUAL_PROD_MAIL_USERNAME
            VITE_APP_NAME=ActuallyFind

            # OAuth Credentials
            GOOGLE_CLIENT_ID=${{ secrets.PRODUCTION_GOOGLE_CLIENT_ID }}
            GOOGLE_CLIENT_SECRET=${{ secrets.PRODUCTION_GOOGLE_CLIENT_SECRET }}
            GOOGLE_REDIRECT_URL=https://actuallyfind.com/auth/google/callback
            FACEBOOK_CLIENT_ID=null
            FACEBOOK_CLIENT_SECRET=null
            FACEBOOK_REDIRECT_URL=https://actuallyfind.com/auth/facebook/callback
            EOF

            # --- Re-append the existing key (if found) or leave a placeholder ---
            if [ -n "$EXISTING_APP_KEY" ]; then
                # Append the existing line (e.g., APP_KEY=base64:...)
                echo "$EXISTING_APP_KEY" >> .env
                echo "‚úÖ Existing APP_KEY preserved."
            else
                # Append a blank APP_KEY line (which we will replace later)
                echo "APP_KEY=" >> .env
                echo "‚ÑπÔ∏è APP_KEY line added. Will be generated on first run."
            fi
            echo "‚úÖ Production .env file securely re-created on VPS."

      # ------------------------------------

      - name: üîê Set Directory Ownership for SCP
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.HOST }}
          username: ${{ env.USER }}
          key: ${{ env.SSH_KEY }}
          script: |
            # 1. Clear files that SCP will upload/overwrite
            rm -f ${{ env.WORK_DIR }}/deploy-prod.sh
            rm -f ${{ env.WORK_DIR }}/actuallyfind-swop.sh
            rm -f ${{ env.WORK_DIR }}/docker-entrypoint.sh

            # 2. Change ownership recursively (requires NOPASSWD in visudo to succeed)
            sudo chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORK_DIR }}

            # 3. FIX: Ensure the directory itself is fully writable by the owner (your SSH user)
            chmod 775 ${{ env.WORK_DIR }}

            echo "‚úÖ Corrected ownership and permissions in ${{ env.WORK_DIR }}"

      # 2. Upload the deployment script to the remote server
      - name: Transfer Deployment Script and Set Permissions
        run: |
          # 1. FIX THE SCP COMMAND
          # SCP the necessary deployment and setup scripts to the VPS
          scp -o StrictHostKeyChecking=no \
              ./app-code/deploy-prod.sh \
              ./app-code/actuallyfind-swop.sh \
              ./app-code/docker-entrypoint.sh \
              ./app-code/docker-compose.yml \
              ${USER}@${HOST}:${WORK_DIR}/

          # 1: Ensure the main deployment script is executable
          ssh ${USER}@${HOST} "chmod +x ${WORK_DIR}/deploy-prod.sh"

          # 2. Ensure the swap script is executable on the remote server
          ssh ${USER}@${HOST} "chmod +x ${WORK_DIR}/actuallyfind-swop.sh"

          # 3. FIX: Ensure the docker-entrypoint.sh is executable on the remote server
          ssh ${USER}@${HOST} "chmod +x ${WORK_DIR}/docker-entrypoint.sh"

      - name: üîê Fix Web Container Directory Permissions
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.HOST }}
          username: ${{ env.USER }}
          key: ${{ env.SSH_KEY }}
          script: |
            # Give full permissions recursively to the directories mounted as volumes
            chmod -R 777 ${{ env.WORK_DIR }}/storage
            chmod -R 777 ${{ env.WORK_DIR }}/bootstrap/cache
            echo "‚úÖ Fixed permissions on storage and cache directories."

      # 3. Execute the script remotely (existing step)
      - name: Execute Deployment Script (Zero Downtime)
        run: |
          # Pass all necessary environment variables and execute the script remotely
          ssh ${{ env.USER }}@${{ env.HOST }} \
            'cd ${{ env.WORK_DIR }} && \
            export WORK_DIR="${{ env.WORK_DIR }}" && \
            export IMAGE_NAME="${{ env.IMAGE_NAME }}" && \
            export APP_URL="${{ env.APP_URL }}" && \
            export WEB_SERVICE_BASE="${{ env.WEB_SERVICE_BASE }}" && \
            export DB_SERVICE="${{ env.DB_SERVICE }}" && \
            export TYPESENSE_SERVICE="${{ env.TYPESENSE_SERVICE }}" && \
            export QUEUE_SERVICE="${{ env.QUEUE_SERVICE }}" && \

            # --- PASS NEW PORT VARIABLES DIRECTLY TO THE SHELL ---
            export DOCKER_LARAVEL_PORT="${{ env.DOCKER_LARAVEL_PORT }}" && \
            export DOCKER_POSTGRES_PORT="${{ env.DOCKER_POSTGRES_PORT }}" && \
            export DOCKER_ADMINER_PORT="${{ env.DOCKER_ADMINER_PORT }}" && \
            export DOCKER_TYPESENSE_PORT="${{ env.DOCKER_TYPESENSE_PORT }}" && \
            # -----------------------------------------------------

            ./deploy-prod.sh'

      # --- NEW STEP: WAIT FOR NGINX RELOAD ---
      - name: ‚è≥ Wait for Nginx Proxy Reload
        run: |
          echo "Giving Nginx 15 seconds to detect the swap and reload configuration."
          sleep 15

      # 4. The External Health Check step (modify the failure block)
      - name: External Health Check (Public URL)
        run: |
          APP_URL="${{ env.APP_URL }}"
          TARGET_SERVICE="actuallyfind-web-green" # Assuming green was the target slot in this run

          echo "üåê Performing external health check..."
          # The 15-second sleep is already correctly implemented before this step
          sleep 5 # Wait a bit more after Nginx reload just in case

          response=$(curl -s -o /dev/null -w "%{http_code}" ${APP_URL} || echo "000")

          if [ "$response" = "200" ]; then
            echo "‚úÖ External health check passed (HTTP $response)"
          else
            echo "‚ùå External health check failed (HTTP $response) at ${APP_URL}"
            echo "--- Fetching Logs for the Target Service (${TARGET_SERVICE}) ---"

            # Fetch the last 50 lines of the target container's logs via SSH
            ssh ${{ env.USER }}@${{ env.HOST }} \
              "docker logs ${TARGET_SERVICE} --tail 50"

            exit 1
          fi

      - name: Cleanup SSH Keys
        if: always()
        run: rm -rf ~/.ssh

      # *** FIX 2 & 3: Switched to softprops/action-gh-release@v1 to eliminate deprecation warnings from the action itself ***
      - name: Create GitHub Release
        if: startsWith(github.ref, 'refs/tags/v')
        uses: softprops/action-gh-release@v1
        env:
          # Use the default token provided by the GitHub Actions runner (needed for write permission)
          GITHUB_TOKEN: ${{ github.token }}
        with:
          tag_name: ${{ github.ref_name }}
          name: Release ${{ github.ref_name }}
          body: |
            ## Deployment Info
            - **Version**: ${{ needs.publish.outputs.version-tag }}
            - **Environment**: Production
            - **Deployed**: ${{ github.event.head_commit.timestamp }}
            - **Commit**: ${{ github.sha }}
          draft: false
          prerelease: false
